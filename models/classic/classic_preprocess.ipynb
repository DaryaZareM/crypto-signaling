{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "J9DvrviVIsMd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# imports"
      ],
      "metadata": {
        "id": "8WzeOGxnUVKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv_dqzYwH23w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2636479-5ccc-42ec-f2f3-4f720e9fc53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "!pip install emoji\n",
        "\n",
        "import re\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from string import digits\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "import math\n",
        "import pickle\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import WordNetLemmatizer\n",
        "from nltk import download as nltk_download\n",
        "from emoji import demojize\n",
        "import emoji\n",
        "import unidecode as ud\n",
        "from nltk import bigrams\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "nltk_download('stopwords')\n",
        "nltk_download('punkt')\n",
        "nltk_download('wordnet')"
      ],
      "metadata": {
        "id": "sYwxrobaH_Nm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25868415-1657-4733-ff38-b2a0272d7eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |â–ˆâ–                              | 10 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–‰                             | 20 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–                           | 30 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                          | 40 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                      | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                    | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                   | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 102 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                | 112 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 122 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              | 133 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ            | 143 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰           | 153 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž         | 163 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹        | 174 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 184 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 194 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 204 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 215 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 225 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235 kB 4.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 175 kB 4.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=36fe36f35c0068b9823b0395e0796d4d3542e47267a292af55a784bd1487213b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data gathering"
      ],
      "metadata": {
        "id": "fcng4K3Hd9Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/crypto-classifier/data'\n",
        "d1=pd.read_csv(f'{path}/new_tag/Darya.v1.csv', encoding='UTF-8',dtype='str')\n",
        "d2=pd.read_csv(f'{path}/tag3/Nargess.v2.csv', encoding='UTF-8',dtype='str')\n",
        "d3=pd.read_csv(f'{path}/tag3/Hana.v2.csv', encoding='UTF-8',dtype='str')\n",
        "d4=pd.read_csv(f'{path}/multy_platform/instagram_tags_1.csv', encoding='UTF-8',dtype='str')\n",
        "d5=pd.read_csv(f'{path}/multy_platform/Reddit_3000_Data_tagged_1.csv', encoding='UTF-8',dtype='str')"
      ],
      "metadata": {
        "id": "2yv7geDaVBiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.concat([d4.rename(columns={'Polarity'\t:'polarity'}),d5]).reset_index(drop=True)\n",
        "data['polarity']=data['polarity'].astype(float).astype(int)\n",
        "labels = {0:'not positive', 1:'positive'}\n",
        "for i in range(len(data['polarity'])):\n",
        "  data['polarity'][i]=labels[data['polarity'][i]]\n",
        "data=data[['text','polarity']]"
      ],
      "metadata": {
        "id": "Fbt4z2fqO9fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2=data"
      ],
      "metadata": {
        "id": "ESXXtqzSPyqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2=d2.iloc[:400,:-2]\n",
        "data=pd.concat([d1,d2])\n",
        "data=pd.concat([data,d3])\n",
        "data=data.rename(columns={'Unnamed: 0.1'\t:'index1'})\n",
        "data=data.rename(columns={'Unnamed: 0'\t:'index0'})\n",
        "data=data[data['ns'].isna()].reset_index(drop=True)\n",
        "data=data.dropna(subset=['concat_fields']).reset_index(drop=True)\n",
        "# data"
      ],
      "metadata": {
        "id": "2T4C-zLveESs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make Uniformity labels\n",
        "data['signal'] = data['signal'].fillna('no signal').apply(lambda x:x.lower())\n",
        "data['polarity'] = data['polarity'].fillna('neutral').apply(lambda x:x.lower())\n",
        "\n",
        "data['signal']=data['signal'].apply(lambda x:'no signal' if x in ['no siganl','no signale','not buy','-','bno signal'] else x)\n",
        "data['signal']=data['signal'].apply(lambda x:'hold' if x in ['bhold','keep'] else x)\n",
        "data['signal']=data['signal'].apply(lambda x:'buy' if x in ['nbuy','positie','positive'] else x)\n",
        "data['polarity']=data['polarity'].apply(lambda x:'neutral' if x in ['nutral','-'] else x)\n",
        "data['polarity']=data['polarity'].apply(lambda x:'negative' if x in ['negetive','negetive\\n'] else x)\n",
        "data['polarity']=data['polarity'].apply(lambda x:'positive' if x in ['positve','positve','positie','posiitve','postive'] else x)\n",
        "print('categories: ',Counter(data['signal']))\n",
        "print('polarity: ',Counter(data['polarity']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1azbhu0pgWeN",
        "outputId": "446e0f2b-f504-43ac-afc5-e7c75a33b478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "categories:  Counter({'buy': 1089, 'no signal': 716, 'sell': 101, 'hold': 21})\n",
            "polarity:  Counter({'positive': 1265, 'neutral': 483, 'negative': 179})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data[['concat_fields','polarity']].rename(columns={'concat_fields'\t:'text'})\n",
        "data = pd.concat([data2.rename(columns={'text':'concat_fields'}),data[['concat_fields','polarity']]]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "JXBRKkv-SDVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# columns\n",
        "['index0', 'index1', 'contributors', 'coordinates', 'created_at',\n",
        "'display_text_range', 'entities', 'favorite_count', 'favorited',\n",
        "'full_text', 'geo', 'id', 'id_str', 'in_reply_to_screen_name',\n",
        "'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
        "'in_reply_to_user_id', 'in_reply_to_user_id_str', 'is_quote_status',\n",
        "'lang', 'place', 'retweet_count', 'retweeted', 'source', 'truncated',\n",
        "'user', 'extended_entities', 'possibly_sensitive', 'retweeted_status',\n",
        "'quoted_status', 'quoted_status_id', 'quoted_status_id_str',\n",
        "'quoted_status_permalink', 'user_sname', 'withheld_copyright',\n",
        "'withheld_in_countries', 'withheld_scope', 'concat_fields',\n",
        "'clean_tweet', 'coins', 'coins2', 'coins3', 'signal', 'polarity',\n",
        "'Ambiguous', 'ns', 'discotion or ad']\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "yUb7S9IoxYEw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# media type"
      ],
      "metadata": {
        "id": "IfBlidxHikdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "data['has_media']=data['extended_entities'].notnull()\n",
        "tm=[]\n",
        "for i,d in enumerate(data['extended_entities']):\n",
        "  try:\n",
        "    if data['has_media'][i]:\n",
        "      tm.append(json.loads(d.replace('\\'','\\\"').replace(' False',' \\\"False\\\"').replace(' True',' \\\"True\\\"').replace(' None',' \\\"None\\\"'))['media'][0]['type'])\n",
        "    else:\n",
        "      tm.append('0')\n",
        "  except:\n",
        "    print(i)\n",
        "    tm.append(-1)\n",
        "data['media_type']=tm\n",
        "print(Counter(data['media_type']))\n",
        "\n",
        "media2integer={'0': 0, 'animated_gif': 1, 'photo': 2, 'video': 3 , -1: 0}\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "data['media_type_int']=data['media_type'].apply(lambda x : media2integer[x])\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "data[['no_media','animated_gif', 'photo','video']]=onehot_encoder.fit_transform(data[['media_type_int']]).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDJC2O2vuG_A",
        "outputId": "fc07185a-0527-4c48-8f3e-554deb9ccdfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1491\n",
            "Counter({'0': 1387, 'photo': 434, 'video': 65, 'animated_gif': 40, -1: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# links"
      ],
      "metadata": {
        "id": "RZDoqZwKDUQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer= lambda x:x.replace('\\\"','\\\";\"').replace('\\'','\\\"').replace('\\\";\"','\\'').replace(' False',' \\\"False\\\"').replace(' True',' \\\"True\\\"').replace(' None',' \\\"None\\\"')\n",
        "\n",
        "links=[]\n",
        "quoted_status = data['quoted_status'].notna()\n",
        "retweeted_status = data['retweeted_status'].notna()\n",
        "for i in range(len(data)):\n",
        "  try:\n",
        "    if quoted_status[i]:\n",
        "      links.append([j['expanded_url'] for j in json.loads(normalizer(data.iloc[i]['quoted_status']))['entities']['urls']]+[j['expanded_url'] for j in json.loads(normalizer(data.iloc[i]['entities']))['urls']])\n",
        "    elif retweeted_status[i]:\n",
        "      links.append([j['expanded_url'] for j in json.loads(normalizer(data.iloc[i]['retweeted_status']))['entities']['urls']])\n",
        "    else:\n",
        "      links.append([j['expanded_url'] for j in json.loads(normalizer(data.iloc[i]['entities']))['urls']])\n",
        "  except:\n",
        "    # print(i)\n",
        "    links.append([])\n",
        "    pass\n",
        "data['links']=np.array(links)"
      ],
      "metadata": {
        "id": "VxzinnDCvUlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# preprocess"
      ],
      "metadata": {
        "id": "GHAzDlz1eBcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_emojis(s):\n",
        "  return [c for c in s if c in emoji.UNICODE_EMOJI['en']]\n",
        "\n",
        "\"\"\" Normalize text \"\"\"\n",
        "def normalizeToken(token):\n",
        "    \"\"\"return normal tweet with mentions and http url\n",
        "    Args:\n",
        "        token ([string]): [a word(a token)]\n",
        "    Returns:\n",
        "        [string]: [normalized token]\n",
        "    \"\"\"\n",
        "    if token.startswith(\"@\"):\n",
        "        return \"@user\"\n",
        "    elif token.lower().startswith(\"http\") or token.lower().startswith(\"www\"):\n",
        "        return \"httpurl\"\n",
        "    else:\n",
        "        return (token)\n",
        "\n",
        "def normalizeTweets(tweets):\n",
        "    \"\"\"function for preprocessing\n",
        "        - demojize\n",
        "        - unidecode\n",
        "        - lower\n",
        "        - lammetize\n",
        "\n",
        "    Args:\n",
        "        tweets ([numpy list]): [list of plane text tweets]\n",
        "\n",
        "    Returns:\n",
        "        [numpy list]: [list of normalized tweets]\n",
        "    \"\"\"\n",
        "\n",
        "    f = open(f\"{path}/englishstop.txt\", \"r\")\n",
        "    stop_wl_1=f.read()\n",
        "    f = open(f\"{path}/stop_words_english.txt\", \"r\")\n",
        "    stop_wl_2=f.read()\n",
        "\n",
        "    punctuations=r'''\"&()*,.:;?[\\]^`{|}~'''\n",
        "\n",
        "    # # replace emojies\n",
        "    tweets=tweets.apply(lambda x:\" \".join(demojize(x, delimiters=(\" \", \" \")).split()))\n",
        "\n",
        "    # # delete numbers and punctuations\n",
        "\n",
        "    tweets = tweets.apply(lambda x: ud.unidecode(x))\n",
        "    tweets = tweets.apply(lambda x: x.translate(str.maketrans(' ', ' ', punctuations)))\n",
        "    # #lower\n",
        "    tweets = tweets.apply(lambda x: x.lower())\n",
        "    # # normalize\n",
        "    lemma = WordNetLemmatizer()\n",
        "    # normTweets = tweets.apply(lambda x: (\" \".join([normalizeToken(token) for token in x.split()])))\n",
        "    normTweets = tweets.apply(lambda x: (\" \".join([lemma.lemmatize(token, pos = \"v\") for token in x.split()])))\n",
        "    normTweets = normTweets.apply(lambda x: (\" \".join([lemma.lemmatize(token, pos = \"n\") for token in x.split()])))\n",
        "\n",
        "    # # remove stopwords\n",
        "    normTweets = normTweets.apply(lambda x: \" \".join([word for word in x.split() if word not in stopwords.words(\"english\")]))\n",
        "    normTweets = normTweets.apply(lambda x: \" \".join([word for word in x.split() if word not in stop_wl_1]))\n",
        "    # normTweets = normTweets.apply(lambda x: \" \".join([word for word in x.split() if word not in stop_wl_2]))\n",
        "\n",
        "    for i in range(len(normTweets)):\n",
        "        if not len(normTweets[i]):\n",
        "             normTweets[i]='nan'\n",
        "    return normTweets\n",
        "\n",
        "def unitext(tweets):\n",
        "    dolars = tweets.apply(lambda x:set([ t.replace('$','') for t in x.split() if t.startswith('$')and len(t)>1 ]))\n",
        "\n",
        "    tweets = tweets.apply(lambda x: (\" \".join([normalizeToken(token) for token in x.split()])))\n",
        "    tweets = tweets.apply(lambda x: re.sub(r\"\\d+\", \" a_number \", str(x)))\n",
        "    ut=[]\n",
        "    for i in range(len(tweets)):\n",
        "      ut.append(unicoin(tweets[i],dolars[i]))\n",
        "    return np.array(ut)\n",
        "\n",
        "def extract_features(mydata):\n",
        "\n",
        "  \"\"\"extract hashta \"\"\"\n",
        "  mydata['hashtags'] = mydata['clean_text'].str.findall(\"(#[^#\\s]+)\")\n",
        "  mydata['dolar'] = mydata['clean_text'].apply(lambda x:set([ t.replace('$','') for t in x.split() if t.startswith('$')and len(t)>1 ]))\n",
        "  print('hashtag extraction done!')\n",
        "\n",
        "  mydata['mentions']=mydata['concat_fields'].str.findall(\"(@[^@\\s]+)\")\n",
        "  print('mention extraction done!')\n",
        "\n",
        "  mydata['emojies'] = mydata['concat_fields'].apply(lambda x: extract_emojis(x))\n",
        "\n",
        "  # data['links']=data['concat_fields'].apply(lambda x: [token  for token in x.split() if token.lower().startswith(\"http\") or token.lower().startswith(\"www\")])\n",
        "  print('link extraction done!')\n",
        "\n",
        "  mydata['tokenied'] = mydata['clean_text'].apply(lambda x:x.split(' '))\n",
        "  print('tokenizing done!')\n",
        "\n",
        "  mydata['bigrams'] = mydata['tokenied'].apply(lambda x: list(bigrams(x)))\n",
        "  mydata['bigrams'] = mydata['bigrams'].apply(lambda x: [str(tupl[0] + ' ' + tupl[1]) for tupl in x])\n",
        "  print('bigram extraction done!')\n",
        "\n",
        "\n",
        "  mydata['num_hashtags']=mydata['hashtags'].apply(lambda x: len(x))\n",
        "  mydata['num_mentions']=mydata['mentions'].apply(lambda x: len(x) )\n",
        "\n",
        "  # NYSE=(UTC -5) 2:30 p.m. to 9 p.m\n",
        "\n",
        "  mydata['created_at']=mydata['created_at'].fillna('2000-10-10 24:00:00+00:00')\n",
        "  mydata['Newyork_stockmarket_time']=False\n",
        "  mydata['Newyork_stockmarket_date']=False\n",
        "  mydata['day_week']=-1\n",
        "  mydata['day_month']=-1\n",
        "  mydata['month']=-1\n",
        "\n",
        "  for i in range(len(mydata)):\n",
        "    x=mydata['created_at'][i]\n",
        "    try:\n",
        "      mydata['Newyork_stockmarket_time'][i] = True if x.split()[1].split('+')[0]>'14:30:00' and x.split()[1].split('+')[0]< '21:00:00' else False\n",
        "      mydata['Newyork_stockmarket_date'][i] = pd.Timestamp(x.split()[0]).dayofweek<5 if x.split()[0]!='2000-10-10'  else False\n",
        "      data['day_week'][i]=pd.Timestamp(x.split()[0]).dayofweek if x.split()[0]!='2000-10-10' else -1\n",
        "      data['day_month'][i]=x.split()[0].split('-')[2] if x.split()[0]!='2000-10-10'  else -1\n",
        "      data['month'][i]=x.split()[0].split('-')[1] if x.split()[0]!='2000-10-10'  else -1\n",
        "\n",
        "    except:\n",
        "      print(i,x)\n",
        "  # mydata['Newyork_stockmarket_time']=mydata['created_at'].fillna('2000-10-10 24:00:00+00:00').apply(lambda x:True if x.split()[1].split('+')[0]>'14:30:00' and x.split()[1].split('+')[0]< '21:00:00' else False).astype(int)\n",
        "  # mydata['Newyork_stockmarket_date']=mydata['created_at'].fillna('0000-00-00 24:00:00+00:00').apply(lambda x:pd.Timestamp(x.split()[0]).dayofweek<5 if x.split()[0]!='2000-10-10'  else False ).astype(int)\n",
        "  mydata['Newyork_stockmarket']=mydata['Newyork_stockmarket_time']*mydata['Newyork_stockmarket_date'].astype(int)\n",
        "\n",
        "\n",
        "  print(' successfull Newyork_stockmarket_time ')\n",
        "\n",
        "  # day of week\n",
        "  # data['day_week']=data['created_at'].fillna('0000-00-00 24:00:00+00:00').apply(lambda x:pd.Timestamp(x.split()[0]).dayofweek if x.split()[0]!='2000-10-10'  else -1 )\n",
        "  # data['day_month']=data['created_at'].fillna('0000-00-00 24:00:00+00:00').apply(lambda x:x.split()[0].split('-')[2] if x.split()[0]!='2000-10-10'  else -1 ).astype('int')\n",
        "  # data['month']=data['created_at'].fillna('0000-00-00 24:00:00+00:00').apply(lambda x:x.split()[0].split('-')[1] if x.split()[0]!='2000-10-10'  else -1 ).astype('int')\n",
        "\n",
        "  return mydata\n",
        "\n",
        "def unicoin(tweet,dolar):\n",
        "  tokens=tweet.split()\n",
        "  for i,w in enumerate(tokens):\n",
        "    if w[0]=='$' or w[0]=='#':\n",
        "      w=w[1:]\n",
        "\n",
        "    if w in dolar or w in list(coins['coin_name']) or w in list(coins['symbol']):\n",
        "      tokens[i]='a_coin_name'\n",
        "\n",
        "  return ' '.join(tokens)\n",
        "\n",
        "coins=pd.read_csv(f'{path}/Top_100_coinMarketCap.csv')\n",
        "coins['with$']=coins['symbol'].apply(lambda x:'$'+x+' ')\n",
        "coins['with#']=coins['symbol'].apply(lambda x:'#'+x+' ')\n",
        "coins['symbol']=coins['symbol'].apply(lambda x:' '+x.upper()+' ')\n",
        "coins\n"
      ],
      "metadata": {
        "id": "Mn32daJAIBCC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0995c3db-25f9-4815-d25d-5c17c74e762c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              cname        coin_name   symbol    with$    with#\n",
              "0     1inch network    1inch network   1INCH   $1inch   #1inch \n",
              "1              aave             aave    AAVE    $aave    #aave \n",
              "2          algorand         algorand    ALGO    $algo    #algo \n",
              "3               amp              amp     AMP     $amp     #amp \n",
              "4           arweave          arweave      AR      $ar      #ar \n",
              "..              ...              ...      ...      ...      ...\n",
              "95  wrapped bitcoin  wrapped bitcoin    WBTC    $wbtc    #wbtc \n",
              "96      xdc network      xdc network     XDC     $xdc     #xdc \n",
              "97              xrp              xrp     XRP     $xrp     #xrp \n",
              "98    yearn.finance    yearn.finance     YFI     $yfi     #yfi \n",
              "99            zcash            zcash     ZEC     $zec     #zec \n",
              "\n",
              "[100 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dab26469-f90d-4124-b9a0-635e4bfe2054\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cname</th>\n",
              "      <th>coin_name</th>\n",
              "      <th>symbol</th>\n",
              "      <th>with$</th>\n",
              "      <th>with#</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1inch network</td>\n",
              "      <td>1inch network</td>\n",
              "      <td>1INCH</td>\n",
              "      <td>$1inch</td>\n",
              "      <td>#1inch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aave</td>\n",
              "      <td>aave</td>\n",
              "      <td>AAVE</td>\n",
              "      <td>$aave</td>\n",
              "      <td>#aave</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>algorand</td>\n",
              "      <td>algorand</td>\n",
              "      <td>ALGO</td>\n",
              "      <td>$algo</td>\n",
              "      <td>#algo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>amp</td>\n",
              "      <td>amp</td>\n",
              "      <td>AMP</td>\n",
              "      <td>$amp</td>\n",
              "      <td>#amp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>arweave</td>\n",
              "      <td>arweave</td>\n",
              "      <td>AR</td>\n",
              "      <td>$ar</td>\n",
              "      <td>#ar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>wrapped bitcoin</td>\n",
              "      <td>wrapped bitcoin</td>\n",
              "      <td>WBTC</td>\n",
              "      <td>$wbtc</td>\n",
              "      <td>#wbtc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>xdc network</td>\n",
              "      <td>xdc network</td>\n",
              "      <td>XDC</td>\n",
              "      <td>$xdc</td>\n",
              "      <td>#xdc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>xrp</td>\n",
              "      <td>xrp</td>\n",
              "      <td>XRP</td>\n",
              "      <td>$xrp</td>\n",
              "      <td>#xrp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>yearn.finance</td>\n",
              "      <td>yearn.finance</td>\n",
              "      <td>YFI</td>\n",
              "      <td>$yfi</td>\n",
              "      <td>#yfi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>zcash</td>\n",
              "      <td>zcash</td>\n",
              "      <td>ZEC</td>\n",
              "      <td>$zec</td>\n",
              "      <td>#zec</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dab26469-f90d-4124-b9a0-635e4bfe2054')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dab26469-f90d-4124-b9a0-635e4bfe2054 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dab26469-f90d-4124-b9a0-635e4bfe2054');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['concat_fields'] = data['concat_fields'].apply(lambda x: x.replace('&amp;','and'))\n",
        "data['clean_text']=normalizeTweets(data['concat_fields'])\n",
        "data['unicode_text_clean']=unitext(data['clean_text'])\n",
        "data['unicode_text_concat']=unitext(data['concat_fields'])\n",
        "\n",
        "data=extract_features(data)"
      ],
      "metadata": {
        "id": "ledItXip-vZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c872931e-2689-4f74-b72d-7cb5ca02775c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hashtag extraction done!\n",
            "mention extraction done!\n",
            "link extraction done!\n",
            "tokenizing done!\n",
            "bigram extraction done!\n",
            "1240 1.47E+18\n",
            "1270 1.50E+18\n",
            "1307 1.41E+18\n",
            "1315 1.39E+18\n",
            "1330 1.45E+18\n",
            "1373 1.47E+18\n",
            "1414 1.44E+18\n",
            "1433 1.44E+18\n",
            "1465 1.36E+18\n",
            "1487 1.45E+18\n",
            "1551 1.41E+18\n",
            "1562 1.50E+18\n",
            "1572 1.40E+18\n",
            "1586 1.47E+18\n",
            "1610 1.44E+18\n",
            "1633 1.41E+18\n",
            "1711 1.47E+18\n",
            "1730 1.46E+18\n",
            "1747 1.46E+18\n",
            "1780 1.44E+18\n",
            "1781 1.35E+18\n",
            "1849 1.47E+18\n",
            "1916 1.47E+18\n",
            "1920 1.41E+18\n",
            " successfull Newyork_stockmarket_time \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['no_punc_clean_tweet'] = data['clean_text'].apply(lambda x: re.sub('[^a-zA-Z0-9#$]+\\s*', ' ',x))\n",
        "data['no_punc_concat_fields'] = data['concat_fields'].apply(lambda x: re.sub('[^a-zA-Z0-9#$]+\\s*', ' ',x))\n",
        "# data['clean_tweet'] = data['clean_text'].apply(lambda x: x.replace('&amp;','and'))\n",
        "data['coins'] = data['no_punc_clean_tweet'].apply(lambda x :  [coins['cname'][i] for i in range(len(coins)) if (coins['coin_name'][i]+' ' in x.lower()) or (coins['symbol'][i] in x) or (coins['with$'][i] in x.lower()) or (coins['with#'][i] in x.lower())] )\n",
        "# print('The number of tweets that has coin names is :',len(clean_main_df))\n",
        "# clean_main_df\n",
        "\n",
        "for i in range(len(data['coins'])):\n",
        "  if ' btc ' in data.iloc[i]['no_punc_clean_tweet'] and 'bitcoin' not in data.iloc[i]['coins'] :\n",
        "    data.iloc[i]['coins'].append('bitcoin')\n",
        "\n",
        "# clean_main_df2=data[data['coins'].apply(lambda x:len(x)!=0)]\n",
        "data['coins2'] = data['no_punc_clean_tweet'].apply(lambda x :  [coins['cname'][i] for i in range(len(coins)) if (' '+coins['coin_name'][i]+' ' in x.lower()) or ('$'+coins['coin_name'][i]+' 'in x.lower()) or ('#'+coins['coin_name'][i]+' ' in x.lower())] )\n",
        "data['coins3'] = data['no_punc_concat_fields'].apply(lambda x :  [coins['cname'][i] for i in range(len(coins)) if (coins['symbol'][i] in x)                    or (coins['with$'][i] in x.lower())            or (coins['with#'][i] in x.lower())] )\n",
        "\n",
        "# print('The number of tweets that has coin names is :',len(data))"
      ],
      "metadata": {
        "id": "dZ3f7_ClMunU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['coins1']='A'\n",
        "for i in range(len(data)):\n",
        "  try:\n",
        "    data['coins1'][i]=  list(set(data['coins2'][i]+data['coins3'][i]))\n",
        "  except:\n",
        "    print(i,data['coins2'][i])\n",
        "data [['coins2','coins3','coins1','coins']]\n",
        "data['coins']=data['coins1']\n",
        "data.drop(columns=['coins2','coins3','coins1','no_punc_clean_tweet','no_punc_concat_fields'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2neTsGL_r6x-",
        "outputId": "2b7f4a63-020c-40b5-f397-cad057015b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   index0               index1 contributors coordinates  \\\n",
              "0                     NaN                  NaN          NaN         NaN   \n",
              "1                     NaN                  NaN          NaN         NaN   \n",
              "2                     234               250964          NaN         NaN   \n",
              "3                     576               137938          NaN         NaN   \n",
              "4                     651               137926          NaN         NaN   \n",
              "...                   ...                  ...          ...         ...   \n",
              "1922                 1037               101371          NaN         NaN   \n",
              "1923                 1183                98633          NaN         NaN   \n",
              "1924                 1398               246043          NaN         NaN   \n",
              "1925                 1345               250982          NaN         NaN   \n",
              "1926  1460083034728935425  1460083034728935424          NaN         NaN   \n",
              "\n",
              "                     created_at display_text_range  \\\n",
              "0     2000-10-10 24:00:00+00:00                NaN   \n",
              "1     2000-10-10 24:00:00+00:00                NaN   \n",
              "2     2020-02-11 23:53:19+00:00           [0, 139]   \n",
              "3     2020-03-17 03:55:01+00:00           [0, 139]   \n",
              "4     2020-03-24 08:25:41+00:00           [0, 213]   \n",
              "...                         ...                ...   \n",
              "1922  2022-03-03 19:22:28+00:00           [0, 125]   \n",
              "1923  2022-03-04 13:35:06+00:00           [0, 144]   \n",
              "1924  2022-03-06 02:39:16+00:00           [0, 107]   \n",
              "1925  2022-03-06 07:26:57+00:00           [0, 119]   \n",
              "1926  2000-10-10 24:00:00+00:00                NaN   \n",
              "\n",
              "                                               entities favorite_count  \\\n",
              "0                                                   NaN            NaN   \n",
              "1                                                   NaN            NaN   \n",
              "2     {'hashtags': [], 'symbols': [], 'urls': [], 'u...              0   \n",
              "3     {'hashtags': [{'indices': [66, 74], 'text': 'B...              0   \n",
              "4     {'hashtags': [], 'symbols': [], 'urls': [], 'u...            216   \n",
              "...                                                 ...            ...   \n",
              "1922  {'hashtags': [], 'symbols': [], 'urls': [{'dis...             15   \n",
              "1923  {'hashtags': [{'indices': [77, 85], 'text': 'B...              0   \n",
              "1924  {'hashtags': [{'indices': [56, 64], 'text': 'B...           3457   \n",
              "1925  {'hashtags': [], 'media': [{'display_url': 'pi...             36   \n",
              "1926                                                NaN          FALSE   \n",
              "\n",
              "     favorited                                          full_text  ...  \\\n",
              "0          NaN                                                NaN  ...   \n",
              "1          NaN                                                NaN  ...   \n",
              "2            0  RT @PeterMcCormack: *Bitcoin Around the World*...  ...   \n",
              "3            0  RT @longhashdata: High leverage in the crypto ...  ...   \n",
              "4            0  Fed printing unlimited money to pump markets =...  ...   \n",
              "...        ...                                                ...  ...   \n",
              "1922     FALSE  4b/ No Ledn customers were affected. @cryptono...  ...   \n",
              "1923     FALSE  RT @dinshoo12345: ðŸ‡ºðŸ‡¦ The Ukrainian government ...  ...   \n",
              "1924     FALSE  JUST IN: The number of addresses holding at le...  ...   \n",
              "1925     FALSE  Conditions â€˜ripeâ€™ for Bitcoin adoption amid ge...  ...   \n",
              "1926        en                                                NaN  ...   \n",
              "\n",
              "                                                bigrams num_hashtags  \\\n",
              "0     [core philosophy, philosophy revolve, revolve ...            2   \n",
              "1     [today's bitcoin, bitcoin upsurge, upsurge coi...            0   \n",
              "2     [bitcoin world, world wbd193, wbd193 -, - colo...            0   \n",
              "3     [high leverage, leverage crypto, crypto market...            1   \n",
              "4     [feed print, print unlimited, unlimited money,...            0   \n",
              "...                                                 ...          ...   \n",
              "1922  [simon dixon, dixon mauricio, mauricio bartlol...            0   \n",
              "1923  [ukraine ukrainian, ukrainian government, gove...            3   \n",
              "1924  [number address, address hold, hold 1000, 1000...            1   \n",
              "1925  [condition 'ripe', 'ripe' bitcoin, bitcoin ado...            0   \n",
              "1926  [people bury, bury yfi, yfi realize, realize a...            0   \n",
              "\n",
              "     num_mentions emojies Newyork_stockmarket_time Newyork_stockmarket_date  \\\n",
              "0               1     [ðŸ‘‡]                    False                    False   \n",
              "1               0      []                    False                    False   \n",
              "2               0      []                    False                     True   \n",
              "3               3      []                    False                     True   \n",
              "4               0      []                    False                     True   \n",
              "...           ...     ...                      ...                      ...   \n",
              "1922            1      []                     True                     True   \n",
              "1923            0     [ðŸ¤¨]                    False                     True   \n",
              "1924            0      []                    False                    False   \n",
              "1925            1      []                    False                    False   \n",
              "1926            0      []                    False                    False   \n",
              "\n",
              "     Newyork_stockmarket day_week day_month month  \n",
              "0                      0       -1        -1    -1  \n",
              "1                      0       -1        -1    -1  \n",
              "2                      0        1        11     2  \n",
              "3                      0        1        17     3  \n",
              "4                      0        1        24     3  \n",
              "...                  ...      ...       ...   ...  \n",
              "1922                   1        3         3     3  \n",
              "1923                   0        4         4     3  \n",
              "1924                   0        6         6     3  \n",
              "1925                   0        6         6     3  \n",
              "1926                   0       -1        -1    -1  \n",
              "\n",
              "[1927 rows x 70 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54c17681-24f9-4949-a973-9a523b34d902\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index0</th>\n",
              "      <th>index1</th>\n",
              "      <th>contributors</th>\n",
              "      <th>coordinates</th>\n",
              "      <th>created_at</th>\n",
              "      <th>display_text_range</th>\n",
              "      <th>entities</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>favorited</th>\n",
              "      <th>full_text</th>\n",
              "      <th>...</th>\n",
              "      <th>bigrams</th>\n",
              "      <th>num_hashtags</th>\n",
              "      <th>num_mentions</th>\n",
              "      <th>emojies</th>\n",
              "      <th>Newyork_stockmarket_time</th>\n",
              "      <th>Newyork_stockmarket_date</th>\n",
              "      <th>Newyork_stockmarket</th>\n",
              "      <th>day_week</th>\n",
              "      <th>day_month</th>\n",
              "      <th>month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000-10-10 24:00:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>[core philosophy, philosophy revolve, revolve ...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[ðŸ‘‡]</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000-10-10 24:00:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>[today's bitcoin, bitcoin upsurge, upsurge coi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>234</td>\n",
              "      <td>250964</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-02-11 23:53:19+00:00</td>\n",
              "      <td>[0, 139]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'urls': [], 'u...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>RT @PeterMcCormack: *Bitcoin Around the World*...</td>\n",
              "      <td>...</td>\n",
              "      <td>[bitcoin world, world wbd193, wbd193 -, - colo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>576</td>\n",
              "      <td>137938</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-03-17 03:55:01+00:00</td>\n",
              "      <td>[0, 139]</td>\n",
              "      <td>{'hashtags': [{'indices': [66, 74], 'text': 'B...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>RT @longhashdata: High leverage in the crypto ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[high leverage, leverage crypto, crypto market...</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>[]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>651</td>\n",
              "      <td>137926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2020-03-24 08:25:41+00:00</td>\n",
              "      <td>[0, 213]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'urls': [], 'u...</td>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>Fed printing unlimited money to pump markets =...</td>\n",
              "      <td>...</td>\n",
              "      <td>[feed print, print unlimited, unlimited money,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1922</th>\n",
              "      <td>1037</td>\n",
              "      <td>101371</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-03-03 19:22:28+00:00</td>\n",
              "      <td>[0, 125]</td>\n",
              "      <td>{'hashtags': [], 'symbols': [], 'urls': [{'dis...</td>\n",
              "      <td>15</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>4b/ No Ledn customers were affected. @cryptono...</td>\n",
              "      <td>...</td>\n",
              "      <td>[simon dixon, dixon mauricio, mauricio bartlol...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1923</th>\n",
              "      <td>1183</td>\n",
              "      <td>98633</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-03-04 13:35:06+00:00</td>\n",
              "      <td>[0, 144]</td>\n",
              "      <td>{'hashtags': [{'indices': [77, 85], 'text': 'B...</td>\n",
              "      <td>0</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>RT @dinshoo12345: ðŸ‡ºðŸ‡¦ The Ukrainian government ...</td>\n",
              "      <td>...</td>\n",
              "      <td>[ukraine ukrainian, ukrainian government, gove...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>[ðŸ¤¨]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1924</th>\n",
              "      <td>1398</td>\n",
              "      <td>246043</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-03-06 02:39:16+00:00</td>\n",
              "      <td>[0, 107]</td>\n",
              "      <td>{'hashtags': [{'indices': [56, 64], 'text': 'B...</td>\n",
              "      <td>3457</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>JUST IN: The number of addresses holding at le...</td>\n",
              "      <td>...</td>\n",
              "      <td>[number address, address hold, hold 1000, 1000...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1925</th>\n",
              "      <td>1345</td>\n",
              "      <td>250982</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-03-06 07:26:57+00:00</td>\n",
              "      <td>[0, 119]</td>\n",
              "      <td>{'hashtags': [], 'media': [{'display_url': 'pi...</td>\n",
              "      <td>36</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>Conditions â€˜ripeâ€™ for Bitcoin adoption amid ge...</td>\n",
              "      <td>...</td>\n",
              "      <td>[condition 'ripe', 'ripe' bitcoin, bitcoin ado...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1926</th>\n",
              "      <td>1460083034728935425</td>\n",
              "      <td>1460083034728935424</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2000-10-10 24:00:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FALSE</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>[people bury, bury yfi, yfi realize, realize a...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1927 rows Ã— 70 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54c17681-24f9-4949-a973-9a523b34d902')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54c17681-24f9-4949-a973-9a523b34d902 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54c17681-24f9-4949-a973-9a523b34d902');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['has_media']=data['has_media'].astype(int)"
      ],
      "metadata": {
        "id": "uwN5AXnmhGYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save"
      ],
      "metadata": {
        "id": "kAkbvJ1Pgxlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=['coins2','coins3','coins1'\t,'no_punc_clean_tweet','no_punc_concat_fields']).to_csv(f\"{path}/tag3/cleanTweet1000.csv\",encoding='utf-8',index=False)\n",
        "# data.to_csv(\"new_tag/cleanTweet1000.csv\",encoding='utf-8',index=False)"
      ],
      "metadata": {
        "id": "LWKkbIC_SxUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{path}/tag3/cleanTweet1000.pickle', 'wb') as fp:\n",
        "    pickle.dump(data.drop(columns=['coins2','coins3','coins1'\t,'no_punc_clean_tweet','no_punc_concat_fields']), fp)"
      ],
      "metadata": {
        "id": "5qy0qRXagrIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GF0GWp9oJgqQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}